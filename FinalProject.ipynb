{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COGS 108 - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a) Condense dat files: block hash, transaction overview\n",
    "Drop irrelevant columns in bh.dat and tx.dat; store result dataframes to bh.dat and tx.dat.\n",
    "\n",
    "Result:\n",
    "\n",
    "bh.dat: \n",
    "\n",
    "| Block ID | Block Timestamp |\n",
    "\n",
    "tx.dat: \n",
    "\n",
    "|Transaction ID | Block ID |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/bh.dat' does not exist: b'data/bh.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-16670b7764f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_block_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbh_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf_transaction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/bh.dat' does not exist: b'data/bh.dat'"
     ]
    }
   ],
   "source": [
    "# file path for data\n",
    "bh_filepath = 'data/bh.dat'\n",
    "tx_filepath = 'data/tx.dat'\n",
    "\n",
    "# read data\n",
    "df_block_hash = pd.read_csv(bh_filepath, sep = '\\t')\n",
    "df_transaction = pd.read_csv(tx_filepath, sep = '\\t')\n",
    "\n",
    "# set column names\n",
    "df_block_hash.columns = ['block ID', 'hash', 'timestamp', 'number of transactions']\n",
    "df_transaction.columns = ['transaction ID', 'block ID', 'input count', 'output count']\n",
    "\n",
    "# drop irrelevant columns\n",
    "df_block_hash.drop(['hash', 'number of transactions'], axis = 1, inplace = True)\n",
    "df_transaction.drop(['input count', 'output count'], axis = 1, inplace = True)\n",
    "\n",
    "# check head after drop\n",
    "print(df_block_hash.head())\n",
    "print(df_transaction.head())\n",
    "\n",
    "# write block hash dataframe to a new dat file\n",
    "bh_drop_filepath = 'data/bh.dat'\n",
    "df_block_hash.to_csv(path_or_buf = bh_drop_filepath, sep = '\\t', index = False, columns = ['block ID', 'timestamp'])\n",
    "\n",
    "tx_drop_filepath = 'data/tx.dat'\n",
    "df_transaction.to_csv(path_or_buf = tx_drop_filepath, sep = '\\t', index = False, \n",
    "                      columns = ['transaction ID', 'block ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b) Condense dat files: transaction input\n",
    "Split txin.dat to small dat files; drop irrelevant columns; store result dataframes to txin_1.dat to txin_11.dat.\n",
    "\n",
    "Result:\n",
    "\n",
    "txin_1.dat - txin_11.dat: \n",
    "\n",
    "| Transaction ID | Address ID |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: data/txin.dat: No such file or directory\r\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'txin/taa' does not exist: b'txin/taa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0dbc3809422a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcurr_output_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxin_output_filepath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdf_txin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_input_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     df_txin.columns = ['transaction ID', 'input sequence', 'previous transaction ID', 'previous output sequence', \n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'txin/taa' does not exist: b'txin/taa'"
     ]
    }
   ],
   "source": [
    "# split transaction_input file\n",
    "!split -l 70000000 data/txin.dat t\n",
    "\n",
    "# set filepath\n",
    "num_txin_file = 11\n",
    "\n",
    "txin_input_filepath = ['txin/taa', 'txin/tab', 'txin/tac', 'txin/tad', 'txin/tae', 'txin/taf', 'txin/tag', 'txin/tah',\n",
    "                      'txin/tai', 'txin/taj', 'txin/tak']\n",
    "txin_output_filepath = ['txin/txin_1.dat', 'txin/txin_2.dat', 'txin/txin_3.dat', 'txin/txin_4.dat', 'txin/txin_5.dat', \n",
    "                        'txin/txin_6.dat', 'txin/txin_7.dat', 'txin/txin_8.dat', 'txin/txin_9.dat', 'txin/txin_10.dat', \n",
    "                        'txin/txin_11.dat']\n",
    "\n",
    "# for loop to drop irrelevant columns in transaction_input\n",
    "for x in range(num_txin_file):\n",
    "    curr_input_filepath = txin_input_filepath[x]\n",
    "    curr_output_filepath = txin_output_filepath[x]\n",
    "    \n",
    "    df_txin = pd.read_csv(curr_input_filepath, sep = '\\t')\n",
    "    \n",
    "    df_txin.columns = ['transaction ID', 'input sequence', 'previous transaction ID', 'previous output sequence', \n",
    "                       'address ID', 'sum']\n",
    "    \n",
    "    df_txin.drop(['input sequence', 'previous transaction ID', 'previous output sequence', 'sum'], \n",
    "                 axis = 1, inplace = True)\n",
    "    \n",
    "    df_txin.to_csv(path_or_buf = curr_output_filepath, sep = '\\t', index = False, \n",
    "                   columns = ['transaction ID', 'address ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c) Condense dat files: transaction output\n",
    "Split txout.dat to small dat files; drop irrelevant columns; store result dataframes to txout_1.dat to txout_12.dat.\n",
    "\n",
    "Result:\n",
    "\n",
    "txout_1.dat - txout_12.dat: \n",
    "\n",
    "| Transaction ID | Address ID |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split transaction_output file\n",
    "!split -l 70000000 data/txout.dat m\n",
    "\n",
    "# set filepath\n",
    "num_txout_file = 12\n",
    "\n",
    "txout_input_filepath = ['txout/maa', 'txout/mab', 'txout/mac', 'txout/mad', 'txout/mae', 'txout/maf', 'txout/mag', \n",
    "                        'txout/mah', 'txout/mai', 'txout/maj', 'txout/mak', 'txout/mal']\n",
    "txout_output_filepath = ['txout/txout_1.dat', 'txout/txout_2.dat', 'txout/txout_3.dat', 'txout/txout_4.dat', \n",
    "                         'txout/txout_5.dat', 'txout/txout_6.dat', 'txout/txout_7.dat', 'txout/txout_8.dat', \n",
    "                         'txout/txout_9.dat', 'txout/txout_10.dat', 'txout/txout_11.dat', 'txout/txout_12.dat']\n",
    "\n",
    "# for loop to drop irrelevant columns in transaction_output\n",
    "for x in range(num_txout_file):\n",
    "    curr_input_filepath = txout_input_filepath[x]\n",
    "    curr_output_filepath = txout_output_filepath[x]\n",
    "    \n",
    "    df_txout = pd.read_csv(curr_input_filepath, sep = '\\t')\n",
    "    \n",
    "    df_txout.columns = ['transaction ID', 'output sequence', 'address ID', 'sum']\n",
    "    \n",
    "    df_txout.drop(['output sequence', 'sum'], axis = 1, inplace = True)\n",
    "    \n",
    "    df_txout.to_csv(path_or_buf = curr_output_filepath, sep = '\\t', index = False, \n",
    "                   columns = ['transaction ID', 'address ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d) Convert UNIX time to standard time\n",
    "Implement a function that converts UNIX to standard time; add a column \"year\" in bh.dat.\n",
    "\n",
    "Before: \n",
    "\n",
    "| Block ID | Block Timestamp |\n",
    "\n",
    "After: \n",
    "\n",
    "| Block ID | Block Timestamp | Month | Year |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "file='bh_simplified.dat'\n",
    "\n",
    "df=pd.read_csv(file, sep='\\t')\n",
    "\n",
    "def getYear(data):\n",
    "    d=datetime.fromtimestamp(data)\n",
    "    return d.timetuple().tm_year\n",
    "def getMonth(data):\n",
    "    d=datetime.fromtimestamp(data)\n",
    "    return d.timetuple().tm_mon\n",
    "\n",
    "df['month']=df['timestamp'].apply(getMonth)\n",
    "df['year']=df['timestamp'].apply(getYear)\n",
    "\n",
    "df.to_csv('bh_readable.dat', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1e) Range of Block IDs for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_filepath = 'data/bh_readable.dat'\n",
    "df_block_hash = pd.read_csv(bh_filepath, sep = '\\t')\n",
    "df_block_hash.columns = ['blockID', 'timestamp', 'month', 'year']\n",
    "df_block_hash.head()\n",
    "\n",
    "range_block_each_year = {}\n",
    "\n",
    "target_year = df_block_hash[\"year\"][0]\n",
    "\n",
    "target_block_start = 1\n",
    "target_block_end = 1\n",
    "\n",
    "for row in df_block_hash.itertuples():\n",
    "    curr_year = row.year\n",
    "    \n",
    "    if curr_year > target_year:\n",
    "        curr_block_id = row.blockID\n",
    "        \n",
    "        target_block_end = curr_block_id - 1\n",
    "        \n",
    "        range_block_each_year[target_year] = (target_block_start, target_block_end)\n",
    "        \n",
    "        target_block_start = curr_block_id\n",
    "        \n",
    "        target_year += 1\n",
    "        \n",
    "    if target_year == 2018:\n",
    "        break\n",
    "        \n",
    "print(range_block_each_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1f) Range of Transaction IDs for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_filepath = 'data/tx.dat'\n",
    "df_tx = pd.read_csv(tx_filepath, sep = '\\t')\n",
    "df_tx.columns = ['transactionID', 'blockID']\n",
    "\n",
    "range_tx_each_year = {}\n",
    "\n",
    "for key in range_block_each_year:\n",
    "    value = range_block_each_year[key]\n",
    "    \n",
    "    block_range_start = value[0]\n",
    "    block_range_end = value[1]\n",
    "    \n",
    "    df_curr = df_tx[df_tx['blockID'] == block_range_start]\n",
    "    df_curr.reset_index()\n",
    "    tx_range_start = df_curr.iloc[0]['transactionID']\n",
    "    \n",
    "    df_curr = df_tx[df_tx['blockID'] == block_range_end]\n",
    "    df_curr.reset_index()\n",
    "    tx_range_end = df_curr.iloc[len(df_curr) - 1]['transactionID']\n",
    "    \n",
    "    range_tx_each_year[key] = (tx_range_start, tx_range_end)\n",
    "    \n",
    "print(range_tx_each_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1g) Re-split tx_in and tx_out dat files to groups of 2-year time periods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used VIM to split up into 2-year chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1h) Range of Address IDs for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hairy/anaconda2/envs/n/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data10 = pd.read_csv('TxinFiles/txin_2010.dat', sep='\\t')\n",
    "data11 = pd.read_csv('TxinFiles/txin_2011.dat', sep='\\t')\n",
    "data12 = pd.read_csv('TxinFiles/txin_2012.dat', sep='\\t')\n",
    "data13 = pd.read_csv('TxinFiles/txin_2013.dat', sep='\\t')\n",
    "data14 = pd.read_csv('TxinFiles/txin_2014.dat', sep='\\t')\n",
    "data15 = pd.read_csv('TxinFiles/txin_2015.dat', sep='\\t')\n",
    "data16 = pd.read_csv('TxinFiles/txin_2016.dat', sep='\\t')\n",
    "data17 = pd.read_csv('TxinFiles/txin_2017.dat', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [data10, data11, data12, data13, data14, data15, data16, data17]\n",
    "years = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in data:\n",
    "    frame['address ID'] = pd.to_numeric(frame['address ID'], errors='coerce', downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_array = []\n",
    "for frame in data:\n",
    "    tx_max = frame['address ID'].max()\n",
    "    max_array.append(tx_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_array = [data10['address ID'].min()]\n",
    "for i in range(len(max_array)):\n",
    "    min_array.append(max_array[i] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2010': (171, 176514),\n",
       " '2011': (176515, 2769557),\n",
       " '2012': (2769558, 8714741),\n",
       " '2013': (8714742, 24822602),\n",
       " '2014': (24822603, 58929852),\n",
       " '2015': (58929853, 115528140),\n",
       " '2016': (115528141, 210026230.0),\n",
       " '2017': (210026231.0, 369453964)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_id_each_year = {}\n",
    "for i in range(len(years)):\n",
    "    range_id_each_year[years[i]] = (min_array[i], max_array[i])\n",
    "pd.DataFrame(range_id_each_year).to_csv('tx.dat', sep='\\t', index=False)\n",
    "range_id_each_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sample Datasets\n",
    "Data files at this point:\n",
    "\n",
    "block hash: bh.dat\n",
    "\n",
    "transaction overview: tx.dat\n",
    "\n",
    "transaction input: txin_2010.dat, txin_2012.dat, txin_2014.dat, txin_2016.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a) Initialize the Dataframe\n",
    "Initialize the following dataframe:\n",
    "\n",
    "| Address ID | Year | NumTX |\n",
    "\n",
    "Address ID: Bitcoin account identifier\n",
    "\n",
    "Year: Year in which the Address ID has its first transaction\n",
    "\n",
    "NumTx: Number of transactions in total belong to that Bitcoin Address ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Addr_Year = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c) Sample Address ID\n",
    "\n",
    "Randomly Sample 100 address IDs in each transaction input/output dat file.\n",
    "\n",
    "Update the following columns in the dataframe:\n",
    "\n",
    "| Address ID | Year |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data10.loc[(data10['address ID'] >= 31617) & (data10['address ID'] <= 176514)]\n",
    "id_2010 = np.array(address.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data11.loc[(data11['address ID'] >= 176515) & (data11['address ID'] <= 2769557)]\n",
    "id_2011 = np.array(address.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_10_11 = id_2010 + id_2011\n",
    "df_Temp=pd.DataFrame()\n",
    "df_Temp['Address ID']=np.unique(id_10_11)\n",
    "df_Temp['Year']='2010'\n",
    "df_Temp['NumTX']='0'\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, df_Temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data12.loc[(data12['address ID'] >= 2769558) & (data12['address ID'] <= 8714741)]\n",
    "id_2012 = np.array(address.sample(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data13.loc[(data13['address ID'] >= 8714742) & (data13['address ID'] <= 24822602)]\n",
    "id_2013 = np.array(address.sample(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_12_13 = id_2012 + id_2013\n",
    "df_Temp=pd.DataFrame()\n",
    "df_Temp['Address ID']=np.unique(id_12_13)\n",
    "df_Temp['Year']='2012'\n",
    "df_Temp['NumTX']='0'\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, df_Temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data14.loc[(data14['address ID'] >= 24822603) & (data14['address ID'] <= 58929852)]\n",
    "id_2014 = np.array(address.sample(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data15.loc[(data15['address ID'] >= 58929853) & (data15['address ID'] <= 115528140)]\n",
    "id_2015 = np.array(address.sample(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_14_15 = id_2014 + id_2015\n",
    "df_Temp=pd.DataFrame()\n",
    "df_Temp['Address ID']=np.unique(id_14_15)\n",
    "df_Temp['Year']='2014'\n",
    "df_Temp['NumTX']='0'\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, df_Temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data16[data16['address ID'].between(115528141, 210026230)]\n",
    "id_2016 = np.array(address.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data17[data17['address ID'].between(210026231, 369453964)]\n",
    "id_2017 = np.array(address.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_16_17 = id_2016 + id_2017\n",
    "df_Temp=pd.DataFrame()\n",
    "df_Temp['Address ID']=np.unique(id_16_17)\n",
    "df_Temp['Year']='2016'\n",
    "df_Temp['NumTX']='0'\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, df_Temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d) Accumulate Number of Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through all the transaction inputs and outputs; accumulate the numbers of transactions for each sample.\n",
    "\n",
    "Update the following columns in the dataframe:\n",
    "\n",
    "| NumTX |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big=pd.concat([data10, data11, data12, data13, data14, data15, data16, data17])\n",
    "vc=big['address ID'].value_counts()\n",
    "datadp=pd.DataFrame(vc)\n",
    "datadp.columns=['NumTX']\n",
    "datadp['Address ID']=datadp.index\n",
    "datadp.reset_index(drop=True)\n",
    "datadp=datadp[datadp['NumTX']>20]\n",
    "#df_Addr_Year=pd.concat([df_Addr_Year, df_Temp])\n",
    "\n",
    "datadp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc=data10['address ID'].value_counts()\n",
    "datadp=pd.DataFrame(vc)\n",
    "datadp.columns=['NumTX']\n",
    "datadp['Address ID']=datadp.index\n",
    "datadp.reset_index(drop=True)\n",
    "datadp=datadp[datadp['NumTX']>20]\n",
    "df_Temp=pd.DataFrame()\n",
    "df_Temp['Address ID']=np.unique(np.array(datadp.sample(500)))\n",
    "df_Temp['Year']='2010'\n",
    "df_Temp['NumTX']='0'\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, df_Temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_10_17 = [data10, data11, data12, data13, data14, data15, data16, data17]\n",
    "data_10_15 = pd.concat([data10, data11, data12, data13, data14, data15])\n",
    "df_Addr_Year['NumTX'] = 0\n",
    "Temp = df_Addr_Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>NumTX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249264</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261000</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261227</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267927</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270661</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Address ID  Year  NumTX\n",
       "0      249264  2010      2\n",
       "1      261000  2010      1\n",
       "2      261227  2010      1\n",
       "3      267927  2010      1\n",
       "4      270661  2010      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in Temp.iterrows():\n",
    "    amountOfTransactions = len(data_10_15[data_10_15['address ID'] == row['Address ID']])\n",
    "    tx = int(df_Addr_Year[df_Addr_Year['Address ID']==row['Address ID']]['NumTX'])\n",
    "    df_Addr_Year.loc[index, 'NumTX'] = tx + amountOfTransactions\n",
    "df_Addr_Year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_16_17 = pd.concat([data16, data17])\n",
    "Temp = df_Addr_Year[df_Addr_Year['Year']==2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>NumTX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249264.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261000.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261227.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267927.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270661.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Address ID  Year  NumTX\n",
       "0    249264.0  2010      0\n",
       "1    261000.0  2010      0\n",
       "2    261227.0  2010      0\n",
       "3    267927.0  2010      0\n",
       "4    270661.0  2010      0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in Temp.iterrows():\n",
    "    amountOfTransactions = len(data_16_17[data_16_17['address ID'] == row['Address ID']])\n",
    "    tx = int(df_Addr_Year[df_Addr_Year['Address ID']==row['Address ID']]['NumTX'])\n",
    "    df_Addr_Year.loc[index, 'NumTX'] = tx + amountOfTransactions\n",
    "df_Addr_Year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>NumTX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249264.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261000.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261227.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267927.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270661.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>272015.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>275881.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>275906.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>285871.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>286566.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>291304.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>293492.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>294266.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>294361.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300378.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>301931.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>302320.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>302392.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>302946.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>305198.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>313809.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>316189.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>318250.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>319963.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>324699.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>325993.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>326661.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>330032.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>331639.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>332642.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>540242018.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>540895951.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>541635189.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>541977001.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>542019500.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>543498705.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>544973781.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>545218107.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>545509021.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>545848646.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>546367526.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>546441638.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>546483646.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>547079589.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>548962805.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>549825333.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>550337912.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>550371937.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>550683214.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>551255148.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>555560735.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>556734128.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>557952019.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>557976580.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>559370246.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>559777156.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>560104582.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>560338835.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>562899896.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>569265589.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4002 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Address ID  Year  NumTX\n",
       "0        249264.0  2010      0\n",
       "1        261000.0  2010      0\n",
       "2        261227.0  2010      0\n",
       "3        267927.0  2010      0\n",
       "4        270661.0  2010      0\n",
       "5        272015.0  2010      0\n",
       "6        275881.0  2010      0\n",
       "7        275906.0  2010      0\n",
       "8        285871.0  2010      0\n",
       "9        286566.0  2010      0\n",
       "10       291304.0  2010      0\n",
       "11       293492.0  2010      0\n",
       "12       294266.0  2010      0\n",
       "13       294361.0  2010      0\n",
       "14       300378.0  2010      0\n",
       "15       301931.0  2010      0\n",
       "16       302320.0  2010      0\n",
       "17       302392.0  2010      0\n",
       "18       302946.0  2010      0\n",
       "19       305198.0  2010      0\n",
       "20       313809.0  2010      0\n",
       "21       316189.0  2010      0\n",
       "22       318250.0  2010      0\n",
       "23       319963.0  2010      0\n",
       "24       324699.0  2010      0\n",
       "25       325993.0  2010      0\n",
       "26       326661.0  2010      0\n",
       "27       330032.0  2010      0\n",
       "28       331639.0  2010      0\n",
       "29       332642.0  2010      0\n",
       "...           ...   ...    ...\n",
       "1970  540242018.0  2016      0\n",
       "1971  540895951.0  2016      0\n",
       "1972  541635189.0  2016      0\n",
       "1973  541977001.0  2016      0\n",
       "1974  542019500.0  2016      0\n",
       "1975  543498705.0  2016      0\n",
       "1976  544973781.0  2016      0\n",
       "1977  545218107.0  2016      0\n",
       "1978  545509021.0  2016      0\n",
       "1979  545848646.0  2016      0\n",
       "1980  546367526.0  2016      0\n",
       "1981  546441638.0  2016      0\n",
       "1982  546483646.0  2016      0\n",
       "1983  547079589.0  2016      0\n",
       "1984  548962805.0  2016      0\n",
       "1985  549825333.0  2016      0\n",
       "1986  550337912.0  2016      0\n",
       "1987  550371937.0  2016      0\n",
       "1988  550683214.0  2016      0\n",
       "1989  551255148.0  2016      0\n",
       "1990  555560735.0  2016      0\n",
       "1991  556734128.0  2016      0\n",
       "1992  557952019.0  2016      0\n",
       "1993  557976580.0  2016      0\n",
       "1994  559370246.0  2016      0\n",
       "1995  559777156.0  2016      0\n",
       "1996  560104582.0  2016      0\n",
       "1997  560338835.0  2016      0\n",
       "1998  562899896.0  2016      0\n",
       "1999  569265589.0  2016      0\n",
       "\n",
       "[4002 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "light=df_Addr_Year[df_Addr_Year['NumTX'].between(2, 40)]\n",
    "print(len(light))\n",
    "plot=light['NumTX'].hist(bins=30)\n",
    "plot.plot()\n",
    "df_Addr_Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Normal Distribution and T-test\n",
    "Apply Normal Distributions and T-tests to the following 2 groups of samples only:\n",
    "\n",
    "Group 1:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2010 or 2011\n",
    "\n",
    "Group 2:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2016 or 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a) Mean number of transactions\n",
    "What is the average number of transactions for address IDs from each of the 2 groups?\n",
    "\n",
    "Get a taste of how different the means are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1205\n",
      "1.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "Name: NumTX, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create series of the number of transactions from each specified group\n",
    "group1=df_Addr_Year[df_Addr_Year['Year']=='2010']['NumTX']\n",
    "group2=df_Addr_Year[df_Addr_Year['Year']=='2016']['NumTX']\n",
    "#Get means\n",
    "print(group1.mean())\n",
    "print(group2.mean())\n",
    "group2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Normal Distribution Test\n",
    "Check that each of the 2 groups has nearly normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NormaltestResult(statistic=5027.140468383037, pvalue=0.0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "skewtest is not valid with less than 8 samples; 2 samples were given.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-96d7b6ec4238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormaltest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormaltest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mnormaltest\u001b[0;34m(a, axis, nan_policy)\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormaltest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskewtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkurtosistest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0mk2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mskewtest\u001b[0;34m(a, axis, nan_policy)\u001b[0m\n\u001b[1;32m   1336\u001b[0m         raise ValueError(\n\u001b[1;32m   1337\u001b[0m             \u001b[0;34m\"skewtest is not valid with less than 8 samples; %i samples\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m             \" were given.\" % int(n))\n\u001b[0m\u001b[1;32m   1339\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     beta2 = (3.0 * (n**2 + 27*n - 70) * (n+1) * (n+3) /\n",
      "\u001b[0;31mValueError\u001b[0m: skewtest is not valid with less than 8 samples; 2 samples were given."
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "from scipy.stats import kstest\n",
    "\n",
    "print(stats.normaltest(group1))\n",
    "print(stats.normaltest(group2))\n",
    "\n",
    "stat, p_val = kstest(group1, 'beta', [7, 10])\n",
    "print('Statistic: \\t{:1.2f} \\nP-Value: \\t{:1.2e}\\n'.format(stat, p_val))\n",
    "check_p_val(p_val, alpha=0.05)\n",
    "stat, p_val = kstest(group2, 'beta', [7, 10])\n",
    "print('Statistic: \\t{:1.2f} \\nP-Value: \\t{:1.2e}\\n'.format(stat, p_val))\n",
    "check_p_val(p_val, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c) Compare Number of Samples and Population\n",
    "Check that the number of samples is < 10 % of the total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% > 8.157515090383227e-06%\n"
     ]
    }
   ],
   "source": [
    "data_10_17 = [data2, data3, data4, data5]#, data6, data7, data8, data9]\n",
    "totalPopulation = 0\n",
    "\n",
    "for frame in data_10_17:\n",
    "    totalPopulation = totalPopulation + len(frame)\n",
    "#sampleTestPercentage = len(group1) / totalPopulation\n",
    "sampleTestPercentage = (len(group1) + len(group2)) / totalPopulation\n",
    "print('10% > ' + str(sampleTestPercentage) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d) T-test\n",
    "Apply the T-test to the 2 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Analysis of Variance/ANOVA\n",
    "Apply ANOVA to all the 4 groups of samples:\n",
    "\n",
    "Group 1:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2010 or 2011\n",
    "\n",
    "Group 2:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2012 or 2013\n",
    "\n",
    "Group 3:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2014 or 2015\n",
    "\n",
    "Group 4:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2016 or 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a) Normal Distribution Test\n",
    "Check that each group has nearly normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b) Compare Number of Samples and Population\n",
    "Check that the number of samples is < 10 % of the total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4c) ANOVA test\n",
    "Apply ANOVA to the 4 groups of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Linear Model\n",
    "Apply a Linear Model to the data.\n",
    "\n",
    "Independent variable:\n",
    "\n",
    "time: month and year when the address ID has its first transaction\n",
    "\n",
    "Dependent variable:\n",
    "\n",
    "NumTx: Number of total transactions for each address ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a) Create Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b) Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c) Predict Number of Transactions from Age of Address ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Privacy/Ethics Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In accordance with the Safe Harbor Method, we removed all account numbers from our data set and replace them with an incrementing account number based on the order of appearance. Our data set does contain dates, but we do not consider this as an identifier because our unit of analysis is on the timescale of years. Which is too broad to be useful with the identification of Bitcoin users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
