{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COGS 108 - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a) Condense dat files: block hash, transaction overview\n",
    "Drop irrelevant columns in bh.dat and tx.dat; store result dataframes to bh.dat and tx.dat.\n",
    "\n",
    "Result:\n",
    "\n",
    "bh.dat: \n",
    "\n",
    "| Block ID | Block Timestamp |\n",
    "\n",
    "tx.dat: \n",
    "\n",
    "|Transaction ID | Block ID |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/bh.dat' does not exist: b'data/bh.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-16670b7764f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_block_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbh_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf_transaction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/bh.dat' does not exist: b'data/bh.dat'"
     ]
    }
   ],
   "source": [
    "# file path for data\n",
    "bh_filepath = 'data/bh.dat'\n",
    "tx_filepath = 'data/tx.dat'\n",
    "\n",
    "# read data\n",
    "df_block_hash = pd.read_csv(bh_filepath, sep = '\\t')\n",
    "df_transaction = pd.read_csv(tx_filepath, sep = '\\t')\n",
    "\n",
    "# set column names\n",
    "df_block_hash.columns = ['block ID', 'hash', 'timestamp', 'number of transactions']\n",
    "df_transaction.columns = ['transaction ID', 'block ID', 'input count', 'output count']\n",
    "\n",
    "# drop irrelevant columns\n",
    "df_block_hash.drop(['hash', 'number of transactions'], axis = 1, inplace = True)\n",
    "df_transaction.drop(['input count', 'output count'], axis = 1, inplace = True)\n",
    "\n",
    "# check head after drop\n",
    "print(df_block_hash.head())\n",
    "print(df_transaction.head())\n",
    "\n",
    "# write block hash dataframe to a new dat file\n",
    "bh_drop_filepath = 'data/bh.dat'\n",
    "df_block_hash.to_csv(path_or_buf = bh_drop_filepath, sep = '\\t', index = False, columns = ['block ID', 'timestamp'])\n",
    "\n",
    "tx_drop_filepath = 'data/tx.dat'\n",
    "df_transaction.to_csv(path_or_buf = tx_drop_filepath, sep = '\\t', index = False, \n",
    "                      columns = ['transaction ID', 'block ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b) Condense dat files: transaction input\n",
    "Split txin.dat to small dat files; drop irrelevant columns; store result dataframes to txin_1.dat to txin_11.dat.\n",
    "\n",
    "Result:\n",
    "\n",
    "txin_1.dat - txin_11.dat: \n",
    "\n",
    "| Transaction ID | Address ID |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: data/txin.dat: No such file or directory\r\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'txin/taa' does not exist: b'txin/taa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0dbc3809422a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcurr_output_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxin_output_filepath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdf_txin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_input_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     df_txin.columns = ['transaction ID', 'input sequence', 'previous transaction ID', 'previous output sequence', \n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/n/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'txin/taa' does not exist: b'txin/taa'"
     ]
    }
   ],
   "source": [
    "# split transaction_input file\n",
    "!split -l 70000000 data/txin.dat t\n",
    "\n",
    "# set filepath\n",
    "num_txin_file = 11\n",
    "\n",
    "txin_input_filepath = ['txin/taa', 'txin/tab', 'txin/tac', 'txin/tad', 'txin/tae', 'txin/taf', 'txin/tag', 'txin/tah',\n",
    "                      'txin/tai', 'txin/taj', 'txin/tak']\n",
    "txin_output_filepath = ['txin/txin_1.dat', 'txin/txin_2.dat', 'txin/txin_3.dat', 'txin/txin_4.dat', 'txin/txin_5.dat', \n",
    "                        'txin/txin_6.dat', 'txin/txin_7.dat', 'txin/txin_8.dat', 'txin/txin_9.dat', 'txin/txin_10.dat', \n",
    "                        'txin/txin_11.dat']\n",
    "\n",
    "# for loop to drop irrelevant columns in transaction_input\n",
    "for x in range(num_txin_file):\n",
    "    curr_input_filepath = txin_input_filepath[x]\n",
    "    curr_output_filepath = txin_output_filepath[x]\n",
    "    \n",
    "    df_txin = pd.read_csv(curr_input_filepath, sep = '\\t')\n",
    "    \n",
    "    df_txin.columns = ['transaction ID', 'input sequence', 'previous transaction ID', 'previous output sequence', \n",
    "                       'address ID', 'sum']\n",
    "    \n",
    "    df_txin.drop(['input sequence', 'previous transaction ID', 'previous output sequence', 'sum'], \n",
    "                 axis = 1, inplace = True)\n",
    "    \n",
    "    df_txin.to_csv(path_or_buf = curr_output_filepath, sep = '\\t', index = False, \n",
    "                   columns = ['transaction ID', 'address ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c) Condense dat files: transaction output\n",
    "Split txout.dat to small dat files; drop irrelevant columns; store result dataframes to txout_1.dat to txout_12.dat.\n",
    "\n",
    "Result:\n",
    "\n",
    "txout_1.dat - txout_12.dat: \n",
    "\n",
    "| Transaction ID | Address ID |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split transaction_output file\n",
    "!split -l 70000000 data/txout.dat m\n",
    "\n",
    "# set filepath\n",
    "num_txout_file = 12\n",
    "\n",
    "txout_input_filepath = ['txout/maa', 'txout/mab', 'txout/mac', 'txout/mad', 'txout/mae', 'txout/maf', 'txout/mag', \n",
    "                        'txout/mah', 'txout/mai', 'txout/maj', 'txout/mak', 'txout/mal']\n",
    "txout_output_filepath = ['txout/txout_1.dat', 'txout/txout_2.dat', 'txout/txout_3.dat', 'txout/txout_4.dat', \n",
    "                         'txout/txout_5.dat', 'txout/txout_6.dat', 'txout/txout_7.dat', 'txout/txout_8.dat', \n",
    "                         'txout/txout_9.dat', 'txout/txout_10.dat', 'txout/txout_11.dat', 'txout/txout_12.dat']\n",
    "\n",
    "# for loop to drop irrelevant columns in transaction_output\n",
    "for x in range(num_txout_file):\n",
    "    curr_input_filepath = txout_input_filepath[x]\n",
    "    curr_output_filepath = txout_output_filepath[x]\n",
    "    \n",
    "    df_txout = pd.read_csv(curr_input_filepath, sep = '\\t')\n",
    "    \n",
    "    df_txout.columns = ['transaction ID', 'output sequence', 'address ID', 'sum']\n",
    "    \n",
    "    df_txout.drop(['output sequence', 'sum'], axis = 1, inplace = True)\n",
    "    \n",
    "    df_txout.to_csv(path_or_buf = curr_output_filepath, sep = '\\t', index = False, \n",
    "                   columns = ['transaction ID', 'address ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d) Convert UNIX time to standard time\n",
    "Implement a function that converts UNIX to standard time; add a column \"year\" in bh.dat.\n",
    "\n",
    "Before: \n",
    "\n",
    "| Block ID | Block Timestamp |\n",
    "\n",
    "After: \n",
    "\n",
    "| Block ID | Block Timestamp | Month | Year |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "file='bh_simplified.dat'\n",
    "\n",
    "df=pd.read_csv(file, sep='\\t')\n",
    "\n",
    "def getYear(data):\n",
    "    d=datetime.fromtimestamp(data)\n",
    "    return d.timetuple().tm_year\n",
    "def getMonth(data):\n",
    "    d=datetime.fromtimestamp(data)\n",
    "    return d.timetuple().tm_mon\n",
    "\n",
    "df['month']=df['timestamp'].apply(getMonth)\n",
    "df['year']=df['timestamp'].apply(getYear)\n",
    "\n",
    "df.to_csv('bh_readable.dat', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1e) Range of Block IDs for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_filepath = 'data/bh_readable.dat'\n",
    "df_block_hash = pd.read_csv(bh_filepath, sep = '\\t')\n",
    "df_block_hash.columns = ['blockID', 'timestamp', 'month', 'year']\n",
    "df_block_hash.head()\n",
    "\n",
    "range_block_each_year = {}\n",
    "\n",
    "target_year = df_block_hash[\"year\"][0]\n",
    "\n",
    "target_block_start = 1\n",
    "target_block_end = 1\n",
    "\n",
    "for row in df_block_hash.itertuples():\n",
    "    curr_year = row.year\n",
    "    \n",
    "    if curr_year > target_year:\n",
    "        curr_block_id = row.blockID\n",
    "        \n",
    "        target_block_end = curr_block_id - 1\n",
    "        \n",
    "        range_block_each_year[target_year] = (target_block_start, target_block_end)\n",
    "        \n",
    "        target_block_start = curr_block_id\n",
    "        \n",
    "        target_year += 1\n",
    "        \n",
    "    if target_year == 2018:\n",
    "        break\n",
    "        \n",
    "print(range_block_each_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1f) Range of Transaction IDs for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_filepath = 'data/tx.dat'\n",
    "df_tx = pd.read_csv(tx_filepath, sep = '\\t')\n",
    "df_tx.columns = ['transactionID', 'blockID']\n",
    "\n",
    "range_tx_each_year = {}\n",
    "\n",
    "for key in range_block_each_year:\n",
    "    value = range_block_each_year[key]\n",
    "    \n",
    "    block_range_start = value[0]\n",
    "    block_range_end = value[1]\n",
    "    \n",
    "    df_curr = df_tx[df_tx['blockID'] == block_range_start]\n",
    "    df_curr.reset_index()\n",
    "    tx_range_start = df_curr.iloc[0]['transactionID']\n",
    "    \n",
    "    df_curr = df_tx[df_tx['blockID'] == block_range_end]\n",
    "    df_curr.reset_index()\n",
    "    tx_range_end = df_curr.iloc[len(df_curr) - 1]['transactionID']\n",
    "    \n",
    "    range_tx_each_year[key] = (tx_range_start, tx_range_end)\n",
    "    \n",
    "print(range_tx_each_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1g) Re-split tx_in and tx_out dat files to groups of 2-year time periods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used VIM to split up into 2-year chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1h) Range of Address IDs for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hairy/anaconda2/envs/n/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data10 = pd.read_csv('TxinFiles/txin_2010.dat', sep='\\t')\n",
    "data11 = pd.read_csv('TxinFiles/txin_2011.dat', sep='\\t')\n",
    "data12 = pd.read_csv('TxinFiles/txin_2012.dat', sep='\\t')\n",
    "data13 = pd.read_csv('TxinFiles/txin_2013.dat', sep='\\t')\n",
    "data14 = pd.read_csv('TxinFiles/txin_2014.dat', sep='\\t')\n",
    "data15 = pd.read_csv('TxinFiles/txin_2015.dat', sep='\\t')\n",
    "data16 = pd.read_csv('TxinFiles/txin_2016.dat', sep='\\t')\n",
    "data17 = pd.read_csv('TxinFiles/txin_2017.dat', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [data10, data11, data12, data13, data14, data15, data16, data17]\n",
    "years = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in data:\n",
    "    frame['address ID'] = pd.to_numeric(frame['address ID'], errors='coerce', downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_array = []\n",
    "for frame in data:\n",
    "    tx_max = frame['address ID'].max()\n",
    "    max_array.append(tx_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_array = [data10['address ID'].min()]\n",
    "for i in range(len(max_array)):\n",
    "    min_array.append(max_array[i] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2010': (171, 176514),\n",
       " '2011': (176515, 2769557),\n",
       " '2012': (2769558, 8714741),\n",
       " '2013': (8714742, 24822602),\n",
       " '2014': (24822603, 58929852),\n",
       " '2015': (58929853, 115528140),\n",
       " '2016': (115528141, 210026230.0),\n",
       " '2017': (210026231.0, 369453964)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_id_each_year = {}\n",
    "for i in range(len(years)):\n",
    "    range_id_each_year[years[i]] = (min_array[i], max_array[i])\n",
    "pd.DataFrame(range_id_each_year).to_csv('tx.dat', sep='\\t', index=False)\n",
    "range_id_each_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sample Datasets\n",
    "Data files at this point:\n",
    "\n",
    "block hash: bh.dat\n",
    "\n",
    "transaction overview: tx.dat\n",
    "\n",
    "transaction input: txin_2010.dat, txin_2012.dat, txin_2014.dat, txin_2016.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a) Initialize the Dataframe\n",
    "Initialize the following dataframe:\n",
    "\n",
    "| Address ID | Year | NumTX |\n",
    "\n",
    "Address ID: Bitcoin account identifier\n",
    "\n",
    "Year: Year in which the Address ID has its first transaction\n",
    "\n",
    "NumTx: Number of transactions in total belong to that Bitcoin Address ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Addr_Year = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c) Sample Address ID\n",
    "\n",
    "Randomly Sample 100 address IDs in each transaction input/output dat file.\n",
    "\n",
    "Update the following columns in the dataframe:\n",
    "\n",
    "| Address ID | Year |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleNumber=200\n",
    "minTxSamp=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address ID</th>\n",
       "      <th>NumTX</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129545</th>\n",
       "      <td>129545</td>\n",
       "      <td>51</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139525</th>\n",
       "      <td>139525</td>\n",
       "      <td>348</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152088</th>\n",
       "      <td>152088</td>\n",
       "      <td>1327</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114114</th>\n",
       "      <td>114114</td>\n",
       "      <td>27</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100647</th>\n",
       "      <td>100647</td>\n",
       "      <td>83</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88221</th>\n",
       "      <td>88221</td>\n",
       "      <td>25</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152971</th>\n",
       "      <td>152971</td>\n",
       "      <td>32</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56257</th>\n",
       "      <td>56257</td>\n",
       "      <td>35</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153157</th>\n",
       "      <td>153157</td>\n",
       "      <td>139</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69456</th>\n",
       "      <td>69456</td>\n",
       "      <td>35</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141467</th>\n",
       "      <td>141467</td>\n",
       "      <td>335</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107072</th>\n",
       "      <td>107072</td>\n",
       "      <td>26</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64727</th>\n",
       "      <td>64727</td>\n",
       "      <td>35</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105008</th>\n",
       "      <td>105008</td>\n",
       "      <td>29</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150245</th>\n",
       "      <td>150245</td>\n",
       "      <td>4966</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145452</th>\n",
       "      <td>145452</td>\n",
       "      <td>1753</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140851</th>\n",
       "      <td>140851</td>\n",
       "      <td>25</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127121</th>\n",
       "      <td>127121</td>\n",
       "      <td>22</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129463</th>\n",
       "      <td>129463</td>\n",
       "      <td>48</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153004</th>\n",
       "      <td>153004</td>\n",
       "      <td>134</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121903</th>\n",
       "      <td>121903</td>\n",
       "      <td>56</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105067</th>\n",
       "      <td>105067</td>\n",
       "      <td>27</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117920</th>\n",
       "      <td>117920</td>\n",
       "      <td>21</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136068</th>\n",
       "      <td>136068</td>\n",
       "      <td>27</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103766</th>\n",
       "      <td>103766</td>\n",
       "      <td>29</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153709</th>\n",
       "      <td>153709</td>\n",
       "      <td>22</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131326</th>\n",
       "      <td>131326</td>\n",
       "      <td>32</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156293</th>\n",
       "      <td>156293</td>\n",
       "      <td>29</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150238</th>\n",
       "      <td>150238</td>\n",
       "      <td>5012</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50372</th>\n",
       "      <td>50372</td>\n",
       "      <td>54</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195055126</th>\n",
       "      <td>195055126</td>\n",
       "      <td>113</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154863420</th>\n",
       "      <td>154863420</td>\n",
       "      <td>49</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130561332</th>\n",
       "      <td>130561332</td>\n",
       "      <td>32</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89170354</th>\n",
       "      <td>89170354</td>\n",
       "      <td>85</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172655495</th>\n",
       "      <td>172655495</td>\n",
       "      <td>30</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162960451</th>\n",
       "      <td>162960451</td>\n",
       "      <td>42</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162000263</th>\n",
       "      <td>162000263</td>\n",
       "      <td>42</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81846562</th>\n",
       "      <td>81846562</td>\n",
       "      <td>42</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64709816</th>\n",
       "      <td>64709816</td>\n",
       "      <td>26</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139378007</th>\n",
       "      <td>139378007</td>\n",
       "      <td>21</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149905846</th>\n",
       "      <td>149905846</td>\n",
       "      <td>36</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151391664</th>\n",
       "      <td>151391664</td>\n",
       "      <td>69</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140902014</th>\n",
       "      <td>140902014</td>\n",
       "      <td>33</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104276395</th>\n",
       "      <td>104276395</td>\n",
       "      <td>79</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135149679</th>\n",
       "      <td>135149679</td>\n",
       "      <td>314</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131076702</th>\n",
       "      <td>131076702</td>\n",
       "      <td>300</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162677245</th>\n",
       "      <td>162677245</td>\n",
       "      <td>30</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171824550</th>\n",
       "      <td>171824550</td>\n",
       "      <td>156</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146962981</th>\n",
       "      <td>146962981</td>\n",
       "      <td>75</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74515027</th>\n",
       "      <td>74515027</td>\n",
       "      <td>34</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156787648</th>\n",
       "      <td>156787648</td>\n",
       "      <td>41</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179131137</th>\n",
       "      <td>179131137</td>\n",
       "      <td>44</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196402377</th>\n",
       "      <td>196402377</td>\n",
       "      <td>75</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120722021</th>\n",
       "      <td>120722021</td>\n",
       "      <td>24</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74409048</th>\n",
       "      <td>74409048</td>\n",
       "      <td>90</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179300752</th>\n",
       "      <td>179300752</td>\n",
       "      <td>25</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145667388</th>\n",
       "      <td>145667388</td>\n",
       "      <td>50</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68284815</th>\n",
       "      <td>68284815</td>\n",
       "      <td>54</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64802492</th>\n",
       "      <td>64802492</td>\n",
       "      <td>407</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28708901</th>\n",
       "      <td>28708901</td>\n",
       "      <td>43</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Address ID  NumTX  Year\n",
       "129545        129545     51  2010\n",
       "139525        139525    348  2010\n",
       "152088        152088   1327  2010\n",
       "114114        114114     27  2010\n",
       "100647        100647     83  2010\n",
       "88221          88221     25  2010\n",
       "152971        152971     32  2010\n",
       "56257          56257     35  2010\n",
       "153157        153157    139  2010\n",
       "69456          69456     35  2010\n",
       "141467        141467    335  2010\n",
       "107072        107072     26  2010\n",
       "64727          64727     35  2010\n",
       "105008        105008     29  2010\n",
       "150245        150245   4966  2010\n",
       "145452        145452   1753  2010\n",
       "140851        140851     25  2010\n",
       "127121        127121     22  2010\n",
       "129463        129463     48  2010\n",
       "153004        153004    134  2010\n",
       "121903        121903     56  2010\n",
       "105067        105067     27  2010\n",
       "117920        117920     21  2010\n",
       "136068        136068     27  2010\n",
       "103766        103766     29  2010\n",
       "153709        153709     22  2010\n",
       "131326        131326     32  2010\n",
       "156293        156293     29  2010\n",
       "150238        150238   5012  2010\n",
       "50372          50372     54  2010\n",
       "...              ...    ...   ...\n",
       "195055126  195055126    113  2016\n",
       "154863420  154863420     49  2016\n",
       "130561332  130561332     32  2016\n",
       "89170354    89170354     85  2016\n",
       "172655495  172655495     30  2016\n",
       "162960451  162960451     42  2016\n",
       "162000263  162000263     42  2016\n",
       "81846562    81846562     42  2016\n",
       "64709816    64709816     26  2016\n",
       "139378007  139378007     21  2016\n",
       "149905846  149905846     36  2016\n",
       "151391664  151391664     69  2016\n",
       "140902014  140902014     33  2016\n",
       "104276395  104276395     79  2016\n",
       "135149679  135149679    314  2016\n",
       "131076702  131076702    300  2016\n",
       "162677245  162677245     30  2016\n",
       "171824550  171824550    156  2016\n",
       "146962981  146962981     75  2016\n",
       "74515027    74515027     34  2016\n",
       "156787648  156787648     41  2016\n",
       "179131137  179131137     44  2016\n",
       "196402377  196402377     75  2016\n",
       "120722021  120722021     24  2016\n",
       "74409048    74409048     90  2016\n",
       "179300752  179300752     25  2016\n",
       "145667388  145667388     50  2016\n",
       "68284815    68284815     54  2016\n",
       "64802492    64802492    407  2016\n",
       "28708901    28708901     43  2016\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Addr_Year=pd.DataFrame()\n",
    "vc=data10['address ID'].value_counts()\n",
    "datadp=pd.DataFrame(vc)\n",
    "datadp.columns=['NumTX']\n",
    "datadp['Address ID']=datadp.index\n",
    "datadp.reset_index(drop=True)\n",
    "datadp=datadp[datadp['NumTX']>minTxSamp]\n",
    "sample=datadp.sample(sampleNumber)\n",
    "Temp=pd.DataFrame(columns=['Address ID', 'NumTX'])\n",
    "Temp['Address ID']=sample['Address ID']\n",
    "Temp['NumTX']=sample['NumTX']\n",
    "Temp['Year']=2010\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, Temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc=data16['address ID'].value_counts()\n",
    "datadp=pd.DataFrame(vc)\n",
    "datadp.columns=['NumTX']\n",
    "datadp['Address ID']=datadp.index\n",
    "datadp.reset_index(drop=True)\n",
    "datadp=datadp[datadp['NumTX']>minTxSamp]\n",
    "sample=datadp.sample(sampleNumber)\n",
    "Temp=pd.DataFrame(columns=['Address ID', 'NumTX'])\n",
    "Temp['Address ID']=sample['Address ID']\n",
    "Temp['NumTX']=sample['NumTX']\n",
    "Temp['Year']=2016\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, Temp])\n",
    "df_Addr_Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d) Accumulate Number of Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through all the transaction inputs and outputs; accumulate the numbers of transactions for each sample.\n",
    "\n",
    "Update the following columns in the dataframe:\n",
    "\n",
    "| NumTX |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_10_17 = [data10, data11, data12, data13, data14, data15, data16, data17]\n",
    "data_10_15 = pd.concat([data10, data11, data12, data13, data14, data15])\n",
    "df_Addr_Year['NumTX'] = 0\n",
    "Temp = df_Addr_Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>NumTX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249264</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261000</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261227</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267927</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270661</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Address ID  Year  NumTX\n",
       "0      249264  2010      2\n",
       "1      261000  2010      1\n",
       "2      261227  2010      1\n",
       "3      267927  2010      1\n",
       "4      270661  2010      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in Temp.iterrows():\n",
    "    amountOfTransactions = len(data_10_15[data_10_15['address ID'] == row['Address ID']])\n",
    "    tx = int(df_Addr_Year[df_Addr_Year['Address ID']==row['Address ID']]['NumTX'])\n",
    "    df_Addr_Year.loc[index, 'NumTX'] = tx + amountOfTransactions\n",
    "df_Addr_Year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_16_17 = pd.concat([data16, data17])\n",
    "Temp = df_Addr_Year[df_Addr_Year['Year']==2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>NumTX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249264.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261000.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261227.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267927.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270661.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Address ID  Year  NumTX\n",
       "0    249264.0  2010      0\n",
       "1    261000.0  2010      0\n",
       "2    261227.0  2010      0\n",
       "3    267927.0  2010      0\n",
       "4    270661.0  2010      0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in Temp.iterrows():\n",
    "    amountOfTransactions = len(data_16_17[data_16_17['address ID'] == row['Address ID']])\n",
    "    tx = int(df_Addr_Year[df_Addr_Year['Address ID']==row['Address ID']]['NumTX'])\n",
    "    df_Addr_Year.loc[index, 'NumTX'] = tx + amountOfTransactions\n",
    "df_Addr_Year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "light=df_Addr_Year[df_Addr_Year['NumTX'].between(100, 1000)]\n",
    "print(len(light))\n",
    "plot=light['NumTX'].hist(bins=30)\n",
    "plot.plot()\n",
    "#df_Addr_Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Normal Distribution and T-test\n",
    "Apply Normal Distributions and T-tests to the following 2 groups of samples only:\n",
    "\n",
    "Group 1:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2010 or 2011\n",
    "\n",
    "Group 2:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2016 or 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a) Mean number of transactions\n",
    "What is the average number of transactions for address IDs from each of the 2 groups?\n",
    "\n",
    "Get a taste of how different the means are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429.48\n",
      "70.97\n"
     ]
    }
   ],
   "source": [
    "#Create series of the number of transactions from each specified group\n",
    "group1=df_Addr_Year[df_Addr_Year['Year']==2010]['NumTX']\n",
    "group2=df_Addr_Year[df_Addr_Year['Year']==2016]['NumTX']\n",
    "#Get means\n",
    "print(group1.mean())\n",
    "print(group2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Normal Distribution Test\n",
    "Check that each of the 2 groups has nearly normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NormaltestResult(statistic=92.00216280558374, pvalue=1.0519235673744788e-20)\n",
      "NormaltestResult(statistic=82.38676647463134, pvalue=1.288074460008949e-18)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "from scipy.stats import kstest\n",
    "\n",
    "print(stats.normaltest(group1))\n",
    "print(stats.normaltest(group2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c) Compare Number of Samples and Population\n",
    "Check that the number of samples is < 10 % of the total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% > 8.157515090383227e-06%\n"
     ]
    }
   ],
   "source": [
    "data_10_17 = [data2, data3, data4, data5]#, data6, data7, data8, data9]\n",
    "totalPopulation = 0\n",
    "\n",
    "for frame in data_10_17:\n",
    "    totalPopulation = totalPopulation + len(frame)\n",
    "#sampleTestPercentage = len(group1) / totalPopulation\n",
    "sampleTestPercentage = (len(group1) + len(group2)) / totalPopulation\n",
    "print('10% > ' + str(sampleTestPercentage) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d) T-test\n",
    "Apply the T-test to the 2 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Analysis of Variance/ANOVA\n",
    "Apply ANOVA to all the 4 groups of samples:\n",
    "\n",
    "Group 1:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2010 or 2011\n",
    "\n",
    "Group 2:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2012 or 2013\n",
    "\n",
    "Group 3:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2014 or 2015\n",
    "\n",
    "Group 4:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2016 or 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a) Normal Distribution Test\n",
    "Check that each group has nearly normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b) Compare Number of Samples and Population\n",
    "Check that the number of samples is < 10 % of the total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4c) ANOVA test\n",
    "Apply ANOVA to the 4 groups of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Linear Model\n",
    "Apply a Linear Model to the data.\n",
    "\n",
    "Independent variable:\n",
    "\n",
    "time: month and year when the address ID has its first transaction\n",
    "\n",
    "Dependent variable:\n",
    "\n",
    "NumTx: Number of total transactions for each address ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a) Create Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b) Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c) Predict Number of Transactions from Age of Address ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Privacy/Ethics Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In accordance with the Safe Harbor Method, we removed all account numbers from our data set and replace them with an incrementing account number based on the order of appearance. Our data set does contain dates, but we do not consider this as an identifier because our unit of analysis is on the timescale of years. Which is too broad to be useful with the identification of Bitcoin users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
