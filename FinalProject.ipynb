{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COGS 108 - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a) Condense dat files: block hash, transaction overview\n",
    "Drop irrelevant columns in bh.dat and tx.dat; store result dataframes to bh.dat and tx.dat.\n",
    "\n",
    "Result:\n",
    "\n",
    "bh.dat: \n",
    "\n",
    "| Block ID | Block Timestamp |\n",
    "\n",
    "tx.dat: \n",
    "\n",
    "|Transaction ID | Block ID |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path for data\n",
    "bh_filepath = 'data/bh.dat'\n",
    "tx_filepath = 'data/tx.dat'\n",
    "\n",
    "# read data\n",
    "df_block_hash = pd.read_csv(bh_filepath, sep = '\\t')\n",
    "df_transaction = pd.read_csv(tx_filepath, sep = '\\t')\n",
    "\n",
    "# set column names\n",
    "df_block_hash.columns = ['block ID', 'hash', 'timestamp', 'number of transactions']\n",
    "df_transaction.columns = ['transaction ID', 'block ID', 'input count', 'output count']\n",
    "\n",
    "# drop irrelevant columns\n",
    "df_block_hash.drop(['hash', 'number of transactions'], axis = 1, inplace = True)\n",
    "df_transaction.drop(['input count', 'output count'], axis = 1, inplace = True)\n",
    "\n",
    "# check head after drop\n",
    "print(df_block_hash.head())\n",
    "print(df_transaction.head())\n",
    "\n",
    "# write block hash dataframe to a new dat file\n",
    "bh_drop_filepath = 'data/bh.dat'\n",
    "df_block_hash.to_csv(path_or_buf = bh_drop_filepath, sep = '\\t', index = False, columns = ['block ID', 'timestamp'])\n",
    "\n",
    "tx_drop_filepath = 'data/tx.dat'\n",
    "df_transaction.to_csv(path_or_buf = tx_drop_filepath, sep = '\\t', index = False, \n",
    "                      columns = ['transaction ID', 'block ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b) Condense dat files: transaction input\n",
    "Split txin.dat to small dat files; drop irrelevant columns; store result dataframes to txin_1.dat to txin_11.dat.\n",
    "\n",
    "Result:\n",
    "\n",
    "txin_1.dat - txin_11.dat: \n",
    "\n",
    "| Transaction ID | Address ID |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split transaction_input file\n",
    "!split -l 70000000 data/txin.dat t\n",
    "\n",
    "# set filepath\n",
    "num_txin_file = 11\n",
    "\n",
    "txin_input_filepath = ['txin/taa', 'txin/tab', 'txin/tac', 'txin/tad', 'txin/tae', 'txin/taf', 'txin/tag', 'txin/tah',\n",
    "                      'txin/tai', 'txin/taj', 'txin/tak']\n",
    "txin_output_filepath = ['txin/txin_1.dat', 'txin/txin_2.dat', 'txin/txin_3.dat', 'txin/txin_4.dat', 'txin/txin_5.dat', \n",
    "                        'txin/txin_6.dat', 'txin/txin_7.dat', 'txin/txin_8.dat', 'txin/txin_9.dat', 'txin/txin_10.dat', \n",
    "                        'txin/txin_11.dat']\n",
    "\n",
    "# for loop to drop irrelevant columns in transaction_input\n",
    "for x in range(num_txin_file):\n",
    "    curr_input_filepath = txin_input_filepath[x]\n",
    "    curr_output_filepath = txin_output_filepath[x]\n",
    "    \n",
    "    df_txin = pd.read_csv(curr_input_filepath, sep = '\\t')\n",
    "    \n",
    "    df_txin.columns = ['transaction ID', 'input sequence', 'previous transaction ID', 'previous output sequence', \n",
    "                       'address ID', 'sum']\n",
    "    \n",
    "    df_txin.drop(['input sequence', 'previous transaction ID', 'previous output sequence', 'sum'], \n",
    "                 axis = 1, inplace = True)\n",
    "    \n",
    "    df_txin.to_csv(path_or_buf = curr_output_filepath, sep = '\\t', index = False, \n",
    "                   columns = ['transaction ID', 'address ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c) Condense dat files: transaction output\n",
    "Split txout.dat to small dat files; drop irrelevant columns; store result dataframes to txout_1.dat to txout_12.dat.\n",
    "\n",
    "Result:\n",
    "\n",
    "txout_1.dat - txout_12.dat: \n",
    "\n",
    "| Transaction ID | Address ID |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split transaction_output file\n",
    "!split -l 70000000 data/txout.dat m\n",
    "\n",
    "# set filepath\n",
    "num_txout_file = 12\n",
    "\n",
    "txout_input_filepath = ['txout/maa', 'txout/mab', 'txout/mac', 'txout/mad', 'txout/mae', 'txout/maf', 'txout/mag', \n",
    "                        'txout/mah', 'txout/mai', 'txout/maj', 'txout/mak', 'txout/mal']\n",
    "txout_output_filepath = ['txout/txout_1.dat', 'txout/txout_2.dat', 'txout/txout_3.dat', 'txout/txout_4.dat', \n",
    "                         'txout/txout_5.dat', 'txout/txout_6.dat', 'txout/txout_7.dat', 'txout/txout_8.dat', \n",
    "                         'txout/txout_9.dat', 'txout/txout_10.dat', 'txout/txout_11.dat', 'txout/txout_12.dat']\n",
    "\n",
    "# for loop to drop irrelevant columns in transaction_output\n",
    "for x in range(num_txout_file):\n",
    "    curr_input_filepath = txout_input_filepath[x]\n",
    "    curr_output_filepath = txout_output_filepath[x]\n",
    "    \n",
    "    df_txout = pd.read_csv(curr_input_filepath, sep = '\\t')\n",
    "    \n",
    "    df_txout.columns = ['transaction ID', 'output sequence', 'address ID', 'sum']\n",
    "    \n",
    "    df_txout.drop(['output sequence', 'sum'], axis = 1, inplace = True)\n",
    "    \n",
    "    df_txout.to_csv(path_or_buf = curr_output_filepath, sep = '\\t', index = False, \n",
    "                   columns = ['transaction ID', 'address ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d) Convert UNIX time to standard time\n",
    "Implement a function that converts UNIX to standard time; add a column \"year\" in bh.dat.\n",
    "\n",
    "Before: \n",
    "\n",
    "| Block ID | Block Timestamp |\n",
    "\n",
    "After: \n",
    "\n",
    "| Block ID | Block Timestamp | Month | Year |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "file='bh_simplified.dat'\n",
    "\n",
    "df=pd.read_csv(file, sep='\\t')\n",
    "\n",
    "def getYear(data):\n",
    "    d=datetime.fromtimestamp(data)\n",
    "    return d.timetuple().tm_year\n",
    "def getMonth(data):\n",
    "    d=datetime.fromtimestamp(data)\n",
    "    return d.timetuple().tm_mon\n",
    "\n",
    "df['month']=df['timestamp'].apply(getMonth)\n",
    "df['year']=df['timestamp'].apply(getYear)\n",
    "\n",
    "df.to_csv('bh_readable.dat', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1e) Range of Block IDs for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_filepath = 'data/bh_readable.dat'\n",
    "df_block_hash = pd.read_csv(bh_filepath, sep = '\\t')\n",
    "df_block_hash.columns = ['blockID', 'timestamp', 'month', 'year']\n",
    "df_block_hash.head()\n",
    "\n",
    "range_block_each_year = {}\n",
    "\n",
    "target_year = df_block_hash[\"year\"][0]\n",
    "\n",
    "target_block_start = 1\n",
    "target_block_end = 1\n",
    "\n",
    "for row in df_block_hash.itertuples():\n",
    "    curr_year = row.year\n",
    "    \n",
    "    if curr_year > target_year:\n",
    "        curr_block_id = row.blockID\n",
    "        \n",
    "        target_block_end = curr_block_id - 1\n",
    "        \n",
    "        range_block_each_year[target_year] = (target_block_start, target_block_end)\n",
    "        \n",
    "        target_block_start = curr_block_id\n",
    "        \n",
    "        target_year += 1\n",
    "        \n",
    "    if target_year == 2018:\n",
    "        break\n",
    "        \n",
    "print(range_block_each_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1f) Range of Transaction IDs for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_filepath = 'data/tx.dat'\n",
    "df_tx = pd.read_csv(tx_filepath, sep = '\\t')\n",
    "df_tx.columns = ['transactionID', 'blockID']\n",
    "\n",
    "range_tx_each_year = {}\n",
    "\n",
    "for key in range_block_each_year:\n",
    "    value = range_block_each_year[key]\n",
    "    \n",
    "    block_range_start = value[0]\n",
    "    block_range_end = value[1]\n",
    "    \n",
    "    df_curr = df_tx[df_tx['blockID'] == block_range_start]\n",
    "    df_curr.reset_index()\n",
    "    tx_range_start = df_curr.iloc[0]['transactionID']\n",
    "    \n",
    "    df_curr = df_tx[df_tx['blockID'] == block_range_end]\n",
    "    df_curr.reset_index()\n",
    "    tx_range_end = df_curr.iloc[len(df_curr) - 1]['transactionID']\n",
    "    \n",
    "    range_tx_each_year[key] = (tx_range_start, tx_range_end)\n",
    "    \n",
    "print(range_tx_each_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1g) Re-split tx_in and tx_out dat files to groups of 2-year time periods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used VIM to split up into 2-year chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1h) Range of Address IDs for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('TxinFiles/txin_2010.dat', sep='\\t')\n",
    "data3 = pd.read_csv('TxinFiles/txin_2011.dat', sep='\\t')\n",
    "data4 = pd.read_csv('TxinFiles/txin_2012.dat', sep='\\t')\n",
    "data5 = pd.read_csv('TxinFiles/txin_2013.dat', sep='\\t')\n",
    "#data6 = pd.read_csv('TxinFiles/txin_2014.dat', sep='\\t')\n",
    "#data7 = pd.read_csv('TxinFiles/txin_2015.dat', sep='\\t')\n",
    "#data8 = pd.read_csv('TxinFiles/txin_2016.dat', sep='\\t')\n",
    "#data9 = pd.read_csv('TxinFiles/txin_2017.dat', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data8' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-05c48644ee84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata8\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata8\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data8' is not defined"
     ]
    }
   ],
   "source": [
    "#data8['address ID'] = pd.to_numeric(data8['address ID'], errors='coerce', downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [data2, data3, data4, data5]#, data6, data7, data8, data9]\n",
    "years = ['2010', '2011', '2012', '2013']#, '2014', '2015', '2016', '2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_array = []\n",
    "for frame in data:\n",
    "    tx_max = frame['address ID'].max()\n",
    "    max_array.append(tx_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_array = [data2['address ID'].min()]\n",
    "for i in range(len(max_array)):\n",
    "    min_array.append(max_array[i] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2010': (171, 176514),\n",
       " '2011': (176515, 2769557),\n",
       " '2012': (2769558, 8714741),\n",
       " '2013': (8714742, 24822602)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_id_each_year = {}\n",
    "for i in range(len(years)):\n",
    "    range_id_each_year[years[i]] = (min_array[i], max_array[i])\n",
    "pd.DataFrame(range_id_each_year).to_csv('tx.dat', sep='\\t', index=False)\n",
    "range_id_each_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sample Datasets\n",
    "Data files at this point:\n",
    "\n",
    "block hash: bh.dat\n",
    "\n",
    "transaction overview: tx.dat\n",
    "\n",
    "transaction input: txin_2010.dat, txin_2012.dat, txin_2014.dat, txin_2016.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b) Initialize the Dataframe\n",
    "Initialize the following dataframe:\n",
    "\n",
    "| Address ID | Year | NumTX |\n",
    "\n",
    "Address ID: Bitcoin account identifier\n",
    "\n",
    "Year: Year in which the Address ID has its first transaction\n",
    "\n",
    "NumTx: Number of transactions in total belong to that Bitcoin Address ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Addr_Year=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c) Sample Address ID\n",
    "\n",
    "Randomly Sample 100 address IDs in each transaction input/output dat file.\n",
    "\n",
    "Update the following columns in the dataframe:\n",
    "\n",
    "| Address ID | Year |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data2['address ID'][data2['address ID'] >= 31617]\n",
    "address = address[address <= 176514]\n",
    "address.drop_duplicates()\n",
    "id_2010 = np.array(address.sample(125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data3['address ID'][data3['address ID'] >= 176515]\n",
    "address = address[address <= 2769557]\n",
    "address.drop_duplicates()\n",
    "id_2011 = np.array(address.sample(125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_10_11 = id_2010 + id_2011\n",
    "df_Temp=pd.DataFrame()\n",
    "df_Temp['Address ID']=id_10_11\n",
    "df_Temp['Year']='2010'\n",
    "df_Temp['NumTX']='0'\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, df_Temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data4['address ID'][data4['address ID'] >= 2769558]\n",
    "address = address[address <= 8714741]\n",
    "address.drop_duplicates()\n",
    "id_2012 = np.array(address.sample(125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data5['address ID'][data5['address ID'] >= 8714742]\n",
    "address = address[address <= 24822602]\n",
    "address.drop_duplicates()\n",
    "id_2013 = np.array(address.sample(125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_12_13 = id_2012 + id_2013\n",
    "df_Temp=pd.DataFrame()\n",
    "df_Temp['Address ID']=id_12_13\n",
    "df_Temp['Year']='2012'\n",
    "df_Temp['NumTX']='0'\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, df_Temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data6['address ID'][data6['address ID'] >= 24822603]\n",
    "address = address[address <= 58929852]\n",
    "address.drop_duplicates()\n",
    "id_2014 = np.array(address.sample(125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data7['address ID'][data7['address ID'] >= 58929853]\n",
    "address = address[address <= 115528140]\n",
    "address.drop_duplicates()\n",
    "id_2015 = np.array(address.sample(125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_14_15 = id_2014 + id_2015\n",
    "df_Temp=pd.DataFrame()\n",
    "df_Temp['Address ID']=id_14_15\n",
    "df_Temp['Year']='2012'\n",
    "df_Temp['NumTX']='0'\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, df_Temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data8['address ID'][data8['address ID'] >= 115528141]\n",
    "address = address[address <= 210026230]\n",
    "address.drop_duplicates()\n",
    "id_2016 = np.array(address.sample(125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = data9['address ID'][data9['address ID'] >= 210026231]\n",
    "address = address[address <= 369453964]\n",
    "address.drop_duplicates()\n",
    "id_2017 = np.array(address.sample(125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_16_17 = id_2016 + id_2017\n",
    "df_Temp=pd.DataFrame()\n",
    "df_Temp['Address ID']=id_16_17\n",
    "df_Temp['Year']='2012'\n",
    "df_Temp['NumTX']='0'\n",
    "df_Addr_Year=pd.concat([df_Addr_Year, df_Temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d) Accumulate Number of Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through all the transaction inputs and outputs; accumulate the numbers of transactions for each sample.\n",
    "\n",
    "Update the following columns in the dataframe:\n",
    "\n",
    "| NumTX |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>NumTX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>763749</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2726955</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>494581</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1700971</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1442127</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>741905</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2284249</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2217016</td>\n",
       "      <td>2010</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1162955</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1570685</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2146049</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1307397</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1806457</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2377976</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2095730</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>734724</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>744396</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1890369</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>419681</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2043868</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2676659</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2123240</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>276147</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>564243</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1306193</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1082563</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2147679</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2763088</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>802278</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2790759</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>20105411</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>20878485</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>30039697</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>17350874</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>17036543</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>15533635</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>13050658</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>20405337</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>15972803</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>20984154</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>21622533</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>19024985</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>16328712</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>20625423</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>29504302</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>16568500</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>26540534</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>16127841</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>27682567</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>23512576</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>17786639</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>26513589</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>20959359</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>27900012</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>23555045</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>18784870</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>23164853</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>29329462</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>21582906</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>25602514</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Address ID  Year  NumTX\n",
       "0        763749  2010      2\n",
       "1       2726955  2010      2\n",
       "2        494581  2010      0\n",
       "3       1700971  2010      1\n",
       "4       1442127  2010      2\n",
       "5        741905  2010      4\n",
       "6       2284249  2010      2\n",
       "7       2217016  2010     16\n",
       "8       1162955  2010      1\n",
       "9       1570685  2010      2\n",
       "10      2146049  2010      2\n",
       "11      1307397  2010      3\n",
       "12      1806457  2010      1\n",
       "13      2377976  2010      1\n",
       "14      2095730  2010      1\n",
       "15       734724  2010      1\n",
       "16       744396  2010      1\n",
       "17      1890369  2010      1\n",
       "18       419681  2010      2\n",
       "19      2043868  2010      1\n",
       "20      2676659  2010      2\n",
       "21      2123240  2010      2\n",
       "22       276147  2010      2\n",
       "23       564243  2010      2\n",
       "24      1306193  2010      2\n",
       "25      1082563  2010      2\n",
       "26      2147679  2010      0\n",
       "27      2763088  2010      5\n",
       "28       802278  2010      2\n",
       "29      2790759  2010      1\n",
       "..          ...   ...    ...\n",
       "95     20105411  2012      2\n",
       "96     20878485  2012      2\n",
       "97     30039697  2012      1\n",
       "98     17350874  2012      2\n",
       "99     17036543  2012      2\n",
       "100    15533635  2012      2\n",
       "101    13050658  2012      1\n",
       "102    20405337  2012      2\n",
       "103    15972803  2012      2\n",
       "104    20984154  2012      1\n",
       "105    21622533  2012      0\n",
       "106    19024985  2012      2\n",
       "107    16328712  2012      2\n",
       "108    20625423  2012      2\n",
       "109    29504302  2012      1\n",
       "110    16568500  2012      3\n",
       "111    26540534  2012      1\n",
       "112    16127841  2012      2\n",
       "113    27682567  2012      1\n",
       "114    23512576  2012      2\n",
       "115    17786639  2012      2\n",
       "116    26513589  2012      1\n",
       "117    20959359  2012      2\n",
       "118    27900012  2012      1\n",
       "119    23555045  2012      2\n",
       "120    18784870  2012      2\n",
       "121    23164853  2012      2\n",
       "122    29329462  2012      0\n",
       "123    21582906  2012      2\n",
       "124    25602514  2012      1\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tx = {}\n",
    "data_10_17 = [data2, data3, data4, data5]#, data6, data7, data8, data9]\n",
    "Temp=df_Addr_Year\n",
    "for index, row in Temp.iterrows():\n",
    "    for frame in data_10_17:\n",
    "        amountOfTransactions = len(frame[frame['address ID'] == row['Address ID']].drop_duplicates())\n",
    "        #print(amountOfTransactions)\n",
    "        df_Addr_Year.loc[index, 'NumTX'] = int(df_Addr_Year[df_Addr_Year['Address ID']==row['Address ID']]['NumTX']) + amountOfTransactions\n",
    "df_Addr_Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Normal Distribution and T-test\n",
    "Apply Normal Distributions and T-tests to the following 2 groups of samples only:\n",
    "\n",
    "Group 1:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2010 or 2011\n",
    "\n",
    "Group 2:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2016 or 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a) Mean number of transactions\n",
    "What is the average number of transactions for address IDs from each of the 2 groups?\n",
    "\n",
    "Get a taste of how different the means are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Normal Distribution Test\n",
    "Check that each of the 2 groups has nearly normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c) Compare Number of Samples and Population\n",
    "Check that the number of samples is < 10 % of the total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d) T-test\n",
    "Apply the T-test to the 2 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Analysis of Variance/ANOVA\n",
    "Apply ANOVA to all the 4 groups of samples:\n",
    "\n",
    "Group 1:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2010 or 2011\n",
    "\n",
    "Group 2:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2012 or 2013\n",
    "\n",
    "Group 3:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2014 or 2015\n",
    "\n",
    "Group 4:\n",
    "\n",
    "Samples of Address IDs that have their first transaction in year 2016 or 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a) Normal Distribution Test\n",
    "Check that each group has nearly normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b) Compare Number of Samples and Population\n",
    "Check that the number of samples is < 10 % of the total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4c) ANOVA test\n",
    "Apply ANOVA to the 4 groups of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Linear Model\n",
    "Apply a Linear Model to the data.\n",
    "\n",
    "Independent variable:\n",
    "\n",
    "time: month and year when the address ID has its first transaction\n",
    "\n",
    "Dependent variable:\n",
    "\n",
    "NumTx: Number of total transactions for each address ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a) Create Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b) Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c) Predict Number of Transactions from Age of Address ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
